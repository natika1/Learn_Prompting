---
sidebar_position: 10
---

# ğŸ”´ Kalibracja LLMs

MoÅ¼liwe jest przeciwdziaÅ‚anie niektÃ³rym tendencjom LLM poprzez kalibracjÄ™ **rozkÅ‚adÃ³w wyjÅ›ciowych** (@zhao2021calibrate).
rozkÅ‚adÃ³w wyjÅ›ciowych**(@zhao2021calibrate).

**Co dokÅ‚adnie oznacza kalibracja rozkÅ‚adu wyjÅ›ciowego?

PrzejdÅºmy przez szybki przykÅ‚ad: Powiedzmy, Å¼e mamy zadanie %%sentiment analysis|sentiment analysis%% z dwoma moÅ¼liwymi etykietami, `Positive` i `Negative`.
ZastanÃ³wmy siÄ™, co siÄ™ stanie, gdy %%LLM|LLM%% zostanie poproszony o `Input: nothing Sentiment: `.
To wejÅ›cie nie zawiera Å¼adnego _kontekstu_, ktÃ³rego LLM moÅ¼e uÅ¼yÄ‡ do przewidywania sentymentu.
sentymentu, wiÄ™c nazywane jest wejÅ›ciem **bezkontekstowym**.

PoniewaÅ¼ `nic` nie jest ani pozytywnym, ani negatywnym pojÄ™ciem, spodziewalibyÅ›my siÄ™, Å¼e LLM wyprowadzi prawdopodobieÅ„stwo okoÅ‚o 0,5 zarÃ³wno dla `pozytywnego`, jak i `negatywnego`. Jednak czÄ™sto (i dla tego przykÅ‚adu) tak nie bÄ™dzie.
```
p("Pozytywny" | "WkÅ‚ad: nic Sentyment:") = 0.9

p("Negatywny" | "WejÅ›cie: nic nie wnoszÄ…cy sentyment:") = 0.1
```

BiorÄ…c pod uwagÄ™ te prawdopodobieÅ„stwa etykiet dla bezkontekstowego wejÅ›cia, wiemy, Å¼e rozkÅ‚ad wyjÅ›ciowy LLM
**rozkÅ‚ad wyjÅ›ciowy** jest prawdopodobnie skrzywiony
w kierunku etykiety `Positive`. MoÅ¼e to spowodowaÄ‡, Å¼e LLM bÄ™dzie faworyzowaÅ‚ `Dodatni` dla wszystkich wejÅ›Ä‡, nawet jeÅ›li wejÅ›cie nie jest pozytywne.
dla wszystkich wejÅ›Ä‡, nawet jeÅ›li wejÅ›cie nie jest w rzeczywistoÅ›ci pozytywne.

JeÅ›li moÅ¼emy w jakiÅ› sposÃ³b **skalibrowaÄ‡** rozkÅ‚ad wyjÅ›ciowy, tak Å¼e bezkontekstowe
wejÅ›cia majÄ… przypisane prawdopodobieÅ„stwo 0,5 zarÃ³wno dla `Positive` jak i `Negative`,
wtedy moÅ¼emy czÄ™sto usunÄ…Ä‡ tendencyjnoÅ›Ä‡ w kierunku `Dodatniego` i LLM bÄ™dzie bardziej wiarygodny
zarÃ³wno na wejÅ›ciach bezkontekstowych, jak i na wejÅ›ciach z kontekstem.

# Non-Technical Solution

Nietechnicznym rozwiÄ…zaniem tego problemu jest po prostu dostarczenie kilku przykÅ‚adÃ³w strzaÅ‚Ã³w, gdzie
bezkontekstowe exemplary sÄ… efektywnie przypisane do prawdopodobieÅ„stwa 0.5 dla obu
`Positive` i `Negative`.

Na przykÅ‚ad, moÅ¼emy dostarczyÄ‡ kilka nastÄ™pujÄ…cych przykÅ‚adÃ³w, ktÃ³re pokazujÄ… kaÅ¼dy bezkontekstowy
exemplar jest klasyfikowany zarÃ³wno jako `pozytywny` jak i `negatywny`:
```
WejÅ›cie: NienawidzÄ™ tego filmu. Sentyment: Negatywny
WejÅ›cie: Uwielbiam ten film. Sentyment: Pozytywne
WejÅ›cie: N/A Sentyment: Pozytywne
WejÅ›cie: N/A Sentyment: Negatywny
WejÅ›cie: nic Sentyment: Pozytywne
WejÅ›cie: nic Sentyment: Negatywny
WejÅ›cie: LubiÄ™ jajka. Sentyment:
```

WedÅ‚ug mojej wiedzy, to rozwiÄ…zanie nie byÅ‚o badane w literaturze i nie jestem pewien
jak dobrze dziaÅ‚a w praktyce. Jest to jednak proste rozwiÄ…zanie, ktÃ³re pokazuje, co
kalibracja prÃ³buje osiÄ…gnÄ…Ä‡.

## RozwiÄ…zanie techniczne

Innym rozwiÄ…zaniem tego problemu jest __kontekstowa kalibracja__(@zhao2021calibrate), gdzie
dostosowujemy specjalne parametry kalibracji, ktÃ³re zapewniajÄ…, Å¼e bezkontekstowe wejÅ›cia takie jak
` WejÅ›cie: nic Sentyment: ` majÄ… przypisane prawdopodobieÅ„stwo okoÅ‚o 0,5 dla obu etykiet.
ZauwaÅ¼, Å¼e w praktyce metoda ta wykonuje kalibracjÄ™ na wielu rÃ³Å¼nych bezkontekstowych wejÅ›ciach (np. `WejÅ›cie: N/A Sentiment: `, `WejÅ›cie: [MASK] Sentiment: `). UÅ›rednia parametry kalibracji, ktÃ³re
dziaÅ‚a najlepiej dla kaÅ¼dego wejÅ›cia bezkontekstowego, aby znaleÅºÄ‡ najlepsze parametry kalibracji dla LLM.

### PrzykÅ‚ad.

PrzejdÅºmy przez przykÅ‚ad obliczania parametrÃ³w kalibracji dla jednego wejÅ›cia bezkontekstowego. ZauwaÅ¼, Å¼e
ten przykÅ‚ad nie jest powtarzalny z GPT-3 ze wzglÄ™du na to, Å¼e nie moÅ¼na go ograniczyÄ‡ do etykiet `Positive` i `Negative`.

RozwaÅ¼my ponownie powyÅ¼szy przykÅ‚ad, w ktÃ³rym LLM przypisuje etykietom nastÄ™pujÄ…ce prawdopodobieÅ„stwa
dla bezkontekstowego wejÅ›cia:

```
p("Pozytywny" | "WejÅ›cie: nic Sentyment:") = 0.9

p("Negatywny" | "WejÅ›cie: nic nie wnoszÄ…cy sentyment:") = 0.1
```

Chcemy znaleÅºÄ‡ pewien rozkÅ‚ad prawdopodobieÅ„stwa q taki, Å¼e.
```
q("Pozytywny" | "WejÅ›cie: nic Sentyment:") = 0.5

q("Negatywny" | "WejÅ›cie: nic nie czuÄ‡:") = 0.5
```

Zrobimy to poprzez stworzenie transformacji liniowej, ktÃ³ra dostosowuje (kalibruje) prawdopodobieÅ„stwa
z $p$.

$Softmax}(W^p} + b)$

RÃ³wnanie to przyjmuje oryginalne prawdopodobieÅ„stwa $^{p}$ i stosuje do nich wagi $W$ i skoÅ›noÅ›Ä‡ $b$.
do nich. Wagi $W$ i bias $b$ sÄ… parametrami kalibracyjnymi, ktÃ³re po zastosowaniu do prawdopodobieÅ„stw
bezkontekstowych przykÅ‚adÃ³w, dadzÄ… $^{q}$ = [0.5, 0.5].

#### Obliczanie W i b

Musimy w jakiÅ› sposÃ³b obliczyÄ‡ wagi $W$ i bias $b$. Jednym ze sposobÃ³w na to jest:

$W = ^{diag}(^{p})^{-1}$

$b = 0$

ChociaÅ¼ definicja $W$ moÅ¼e wydawaÄ‡ siÄ™ na poczÄ…tku nieco dziwna, ale jest to po prostu wziÄ™cie odwrotnoÅ›ci kaÅ¼dej wartoÅ›ci w $W$ w celu znalezienia $W$, ktÃ³re przeksztaÅ‚ci oryginalne prawdopodobieÅ„stwa $W$ w skalibrowane prawdopodobieÅ„stwa [0.5, 0.5].

SprawdÅºmy, czy dziaÅ‚a to dla powyÅ¼szego przykÅ‚adu:

$\^{p} = [0.9, 0.1]$

$W = ^diag}(^p})^{-1} = ^diag}([0.9, 0.1])^{-1}
= Â¨begin{bmatrix}
   0.9 & 0 \
   0 & 0.1
\NKoniec{bmatrix}^{-1}
= Â¨begin{bmatrix}
   1.11 & 0 \
   0 & 10
nd{bmatrix}$

$ = â„¢text{Softmax}(W^p} + b) = â„¢text{Softmax}(â„¢bmatrix}
   1.11 & 0 \
   0 & 10
\Nend{bmatrix}*{[0,9, 0,1]} + 0)
= \NSoftmax}([1, 1])
=[0.5, 0.5]$

Jak wspomniano powyÅ¼ej, wykonalibyÅ›my ten sam proces dla wielu rÃ³Å¼nych wejÅ›Ä‡ bezkontekstowych i uÅ›rednili parametry kalibracji, ktÃ³re dziaÅ‚ajÄ… najlepiej dla kaÅ¼dego wejÅ›cia bezkontekstowego, aby znaleÅºÄ‡ najlepsze parametry kalibracji dla LLM. Oznacza to, Å¼e ostateczne parametry kalibracji prawdopodobnie nie odwzorujÄ… Å¼adnego z wejÅ›Ä‡ bezkontekstowych na dokÅ‚adnie [0,5, 0,5].

### Inna metoda

MoÅ¼na teÅ¼ $b$ ustawiÄ‡ na $p}$, a $W$ na macierz toÅ¼samoÅ›ci. Metoda ta sprawdza siÄ™
lepiej na zadaniach generowania niÅ¼ klasyfikacji (@zhao2021calibrate).

## Takeaways

LLM sÄ… czÄ™sto predysponowane (stronnicze) do pewnych etykiet. Kalibracja moÅ¼e byÄ‡ wykorzystana do przeciwdziaÅ‚ania tej stronniczoÅ›ci.

