---
sidebar_position: 1
---

#  Soft Prompts

Dostrajanie podpowiedzi (@lester2021power), alternatywa dla dostrajania modelu (@khashabi2021prompt), zamra偶a wagi modelu i aktualizuje parametry podpowiedzi. Wynikowa podpowied藕 jest "mikk podpowiedzi".


import Image from "../assets/prompt_tuning.png";

<div style={{textAlign: 'center'}}>.
  <img src={Image} style={{width: "500px"}} />
</div>

<div style={{textAlign: 'center'}}>
Model Tuning vs Prompt Tuning (Lester et al.)
</div>

Powy偶szy obrazek kontrastuje strojenie modelu z dostrajaniem podpowiedzi.
W strojeniu modelu, dostrajasz ten sam model na r贸偶nych zadaniach. To daje Ci
kilka r贸偶nych modeli, z kt贸rymi niekoniecznie mo偶na atwo czy wejcia.

Z drugiej strony, strojenie podpowiedzi pozwala u偶ywa tego samego modelu do wszystkich zada. Ty
Wystarczy tylko doczy odpowiednie podpowiedzi w czasie wnioskowania, co uatwia
r贸偶nych zada. Jest to prawie taka sama zaleta, jak ma zwyke podpowiadanie
ma. Dodatkowo, mikkie podpowiedzi wytrenowane dla jednego modelu w wielu zadaniach
w wielu zadaniach bd czsto miay t sam dugo tokena.

## Jak to dziaa

Aby zrozumie podstawow logik stojc za mikkimi podpowiedziami, pomylmy o tym, jak dziaa **modelowe wnioskowanie**
na danej podpowiedzi: `Co to jest 2+2?`.

1) Mo偶e by tokenizowane jako `co, 's, 2, +, 2, ?`.

2) Nastpnie ka偶dy token zostanie przekonwertowany na wektor wartoci.

3) Ten wektor wartoci mo偶na uzna za parametry modelu. Model mo偶e by dalej
trenowa, dostosowujc jedynie wagi tych podpowiedzi.

Zauwa偶, 偶e gdy tylko zaczniemy aktualizowa te wagi, wektory token贸w nie bd ju偶
ju偶 nie odpowiadaj rzeczywistym osadzeniom ze sownika.

# Wyniki

Prompt tuning sprawdza si lepiej w przypadku wikszych modeli. Wiksze modele wymagaj r贸wnie偶 mniej
soft token贸w zachty. Niezale偶nie od tego, wicej ni偶 20 token贸w nie daje znaczcego wzrostu wydajnoci.

