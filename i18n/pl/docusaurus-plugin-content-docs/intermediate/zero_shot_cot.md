---
sidebar_position: 4
---

#  Zero Shot Chain of Thought


Zero Shot Chain of Thought (Zero-shot-CoT) prompting (@kojima2022large) jest
kontynuacj %%CoT prompting|CoT prompting%% (@wei2022chain), kt贸ra wprowadza niesamowicie
prost podpowied藕 zerowego strzau. Odkrywaj, 偶e poprzez doczenie s贸w "**Pomylmy krok po kroku
krok po kroku.**" na kocu pytania, LLM s w stanie wygenerowa acuch
myli, kt贸re odpowiadaj na pytanie. Z tego acucha myli, s w stanie
wydoby bardziej dokadne odpowiedzi.

import ZSImage from '@site/docs/assets/zero_shot.png';

<div style={{textAlign: 'center'}}>.
  <img src={ZSImage} style={{width: "500px"}} />
</div>

<div style={{textAlign: 'center'}}>
Zero Shot CoT (Kojima et al.)
</div>

Technicznie rzecz biorc, peny proces Zero-shot-CoT obejmuje dwie oddzielne podpowiedzi/kompletacje.
Na poni偶szym obrazku, g贸rna baka po lewej stronie generuje acuch myli, podczas gdy g贸rna baka po
prawej przyjmuje dane wyjciowe z pierwszej podpowiedzi (w tym sam pierwsz podpowied藕),
i wydobywa odpowied藕 z acucha myli. Ta druga zachta to zachta typu _self augmented_.

import ZSProcessImage from '@site/docs/assets/zero_shot_example.png';

<div style={{textAlign: 'center'}}>.
  <img src={ZSProcessImage} style={{szeroko: "500px"}} />
</div>

<div style={{textAlign: 'center'}}>
Peny proces Zero Shot CoT (Kojima i in.)
</div>

## Przykad.

Oto kilka dem (kt贸re wykonuj tylko ekstrakcj rozumowania). To pierwsze
pokazuje GPT-3 (davinci-003), kt贸ry nie radzi sobie z prostym pytaniem matematycznym, podczas gdy drugie demo u偶ywa podpowiedzi
Zero-shot-CoT i pomylnie rozwizuje problem. Zapraszamy do wprowadzenia swojego
OpenAI API key (kliknij Generate) i pobaw si przykadami. Zwr贸 uwag, o ile prostsze
podpowied藕 Zero-shot-CoT jest prostsza od podpowiedzi CoT.

#### Nieprawidowo

<div trydyno-embed="" openai-model="text-davinci-003" initial-prompt="Jeli Jan ma 5 gruszek, potem zjada 2, i kupuje jeszcze 5, a potem daje 3 swojemu przyjacielowi, to ile ma gruszek?" initial-response="Jan ma 8 gruszek." max-tokens="256" box-rows="3" model-temp="0.7" top-p="1"></div>


#### Prawidowo

<div trydyno-embed="" openai-model="text-davinci-003" initial-prompt="Jeli Jan ma 5 gruszek, nastpnie zjada 2, i kupuje jeszcze 5, po czym daje 3 swojemu przyjacielowi, to ile ma gruszek?" initial-response="Jan zaczyna z 5 gruszkami. Zjada 2 gruszki, zostawiajc mu 3 gruszki. Kupuje jeszcze 5 gruszek, co daje mu cznie 8 gruszek. Oddaje 3 gruszki swojemu przyjacielowi, pozostawiajc mu tylko 5 gruszek." max-tokens="256" box-rows="5" model-temp="0.7" top-p="1"></div>

## Wyniki
Zero-shot-CoT by r贸wnie偶 skuteczny w poprawie wynik贸w w zadaniach arytmetycznych, commonsense,
i rozumowania symbolicznego. Jednak, co nie jest zaskakujce, zazwyczaj nie by tak
jak podpowiedzi CoT. Wa偶nym przypadkiem u偶ycia Zero-shot-CoT jest uzyskanie
kilku przykad贸w dla podpowiedzi CoT jest trudne.

# Ablations of Interest

Kojima i in. eksperymentuj z wieloma r贸偶nymi podpowiedziami typu "Zero-shot-CoT
(np. "Rozwi偶my ten problem dzielc go na kroki." lub "Pomylmy o tym logicznie."), ale stwierdzaj, 偶e "Mylmy krok po kroku" jest najbardziej efektywne dla ich
wybranych zada.



## Notes

Krok ekstrakcji czsto musi by specyficzny dla danego zadania, co czyni Zero-Shot-CoT mniej
generalizacj, ni偶 wydaje si to na pocztku.

Anegdotycznie stwierdziem, 偶e podpowiedzi w stylu Zero-shot-CoT s czasami skuteczne
w poprawieniu dugoci ukoczenia zada generatywnych. Na przykad, rozwa偶
standardow podpowied藕 `Napisz histori o 偶abie i grzybie, kt贸re zostaj przyjaci贸mi.`
Dodanie s贸w `Pomylmy krok po kroku.` na kocu tej zachty prowadzi do
znacznie du偶sze zakoczenie.



