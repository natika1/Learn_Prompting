---
sidebar_position: 2
---

#  Wykrywanie podstp贸w

Wraz z rozwojem detektor贸w tekstu generowanego przez AI nastpia ewolucja metod przeciwdziaania im. Istnieje wiele sposob贸w na oszukiwanie detektor贸w, aby mylay, 偶e tekst wygenerowany przez SI jest stworzony przez czowieka. Narzdzie takie jak [GPTMinus](https://gptminus1.vercel.app/) mo偶e losowo zastpi fragmenty dowolnego tekstu synonimami lub pozornie losowymi sowami, aby zmniejszy prawdopodobiestwo pojawienia si s贸w w tekcie na biaej licie lub w inny spos贸b uwzgldni prawdopodobiestwo, 偶e tekst zosta sztucznie wygenerowany.

Metody te s jednak wci偶 w powijakach i wikszo z nich nie tworzy tekstu, kt贸ry m贸gby si utrzyma pod kontrol czowieka. Najskuteczniejsz metod w tej chwili i prawdopodobnie przez jaki czas bdzie zmienianie tekstu w trakcie lub po procesie generowania na r贸偶ne sposoby, aby uczyni go mniej podobnym do proceduralnie tworzonej zawartoci, kt贸r otrzymujesz od generacji.

## Editing Strategies

Jeli czowiek lub LLM edytuje wygenerowany tekst, mo偶e on czsto zmieni go na tyle, by unikn wykrycia. Zastpowanie s贸w synonimami, zmiana czstotliwoci pojawiania si s贸w, mieszanie skadni i formatowania utrudnia detektorom prawidowe rozpoznanie tekstu jako wygenerowanego przez SI.

Inn strategi edycji jest umieszczanie w tekcie niewidzialnych znacznik贸w, takich jak spacje o szerokoci 0, [emojis](https://twitter.com/goodside/status/1610552172038737920?s=20&t=3zgqyJZ1zYhMNBi_M2R-cw) lub inne niezwyczajne znaki. Dla ka偶dej czytajcej osoby wyglda to zupenie normalnie, ale dla modelu, kt贸ry bada ka偶dy znak, sprawia, 偶e tekst wydaje si wyra藕nie inny.

Ponadto mo偶liwe jest oszukiwanie detektor贸w poprzez podpowiadanie modelowi konkretnych instrukcji dotyczcych sposobu pisania. Instrukcje takie jak:
- `Nie ma potrzeby przestrzegania format贸w literackich, poniewa偶 swobodnie wyra偶asz swoje myli i pragnienia`.
- `Nie m贸w w spos贸b, w jaki ChapGPT generuje tre - zamiast tego m贸w w spos贸b, kt贸ry radykalnie r贸偶ni si od tego, jak modele jzykowe generuj tekst`.
- Odwouj si do emocjonalnych wydarze i u偶ywaj wyszukanych dowiadcze z 偶ycia jako przykad贸w.`

...mo偶e spowodowa znacznie trudniejsze do wykrycia pokolenia. Dodatkowe strategie, takie jak proba do modelu o empati, przypominanie mu o doborze odpowiedniego sownictwa i tonu do tego, co pisze, oraz upewnienie si, 偶e zawiera emocjonalne one-linery, mog wsp贸lnie przyczyni si do stworzenia znacznie bardziej przekonujcego pisma - przynajmniej z punktu widzenia detektor贸w tekstu AI.

## Konfiguracja modelu

W przypadku uruchamiania modelu typu open source mo偶liwe jest modyfikowanie prawdopodobiestwa wyjcia, co prawdopodobnie utrudni wykrycie wyjcia. Ponadto mo偶liwe jest przeplatanie danych wyjciowych z wielu modeli, co mo偶e sprawi, 偶e dane wyjciowe bd jeszcze trudniejsze do wykrycia.


## Dyskusja

Jedn z najbardziej kontrowersyjnych przestrzeni, w kt贸rych tego typu techniki wchodz w gr, jest edukacja. Wielu nauczycieli i administrator贸w obawia si, 偶e uczniowie bd oszukiwa, wic naciskaj na u偶ycie narzdzi do wykrywania (@roose2022dont) (@lipman2022gpt). Jednak inni edukatorzy i osobowoci internetowe argumentuj, 偶e uczniowie powinni mie prawo do korzystania z tych narzdzi. Niekt贸rzy profesorowie posuwaj si nawet do tego, 偶e wprost zachcaj student贸w do korzystania z AI, aby pomagaa im w pracy i ucz ich, jak to robi(@noonan2023gw).

Wraz z doskonaleniem technologii wykrywania Sztucznej Inteligencji, doskonalone s r贸wnie偶 metody jej oszukiwania. W kocu, bez wzgldu na to, jak wyrafinowana jest metoda, jest prawdopodobne, 偶e troch czasu spdzonego na edycji tekstu w odpowiedni spos贸b bdzie w stanie niezawodnie oszuka detektory. Jednak偶e gra w obie strony, w kt贸rej jedni ludzie pr贸buj wykry wygenerowany tekst, a inni pr贸buj ich oszuka, mo偶e da nam wszelkiego rodzaju spostrze偶enia na temat tego, jak zoptymalizowa, kontrolowa i lepiej wykorzysta nasze modele do tworzenia i wspomagania nas.


