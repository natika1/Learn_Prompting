---
sidebar_position: 1
---

#  Wykrywanie tekstu wygenerowanego przez AI

Wykrywanie tekstu wygenerowanego przez SI to du偶y problem dla badaczy i edukator贸w zajmujcych si bezpieczestwem,
midzy innymi. Narzdzia takie jak [GPTZero](https://gptzero.me), [detektor GPT2](https://openai-openai-detector.hf.space) oraz [detektory dwujzyczne](https://github.com/Hello-SimpleAI/chatgpt-comparison-detection) odniosy znaczcy sukces,
Mo偶na je jednak [oszuka](https://learnprompting.org/docs/miscl/trickery).

OpenAI i inni badacze(@bansal2022certified)(@gu2022watermarking) pracuj nad wprowadzeniem statystycznego znaku wodnego do generowanego przez siebie tekstu, ale i to mo偶na oszuka modyfikujc du偶e porcje tekstu.

Problem wykrywania tekstu przez AI bdzie prawdopodobnie wycigiem zbroje w miar wprowadzania nowych modeli i nowych metod wykrywania. Wiele firm ju偶 zaczo budowa rozwizania, kt贸re jak twierdz s bardzo skuteczne, ale trudno to udowodni, zwaszcza, 偶e modele zmieniaj si w czasie.

W tym artykule om贸wimy niekt贸re z obecnych metod wykrywania tekstu generowanego przez AI, a w nastpnym kilka sposob贸w, kt贸re ludzie znale藕li, aby je oszuka.

# OpenAI Text Classifier

OpenAI Text Classifier](https://platform.openai.com/ai-text-classifier) jest do dobr pr贸b stworzenia uniwersalnego detektora tekst贸w AI.
Poprzez wytrenowanie modelu na du偶ej iloci danych wygenerowanych przez SI oraz tekst贸w napisanych przez czowieka o podobnej jakoci, detektor jest w stanie obliczy prawdopodobiestwo, 偶e dany tekst zosta stworzony przez LLM.

Ma kilka ogranicze - nie akceptuje 偶adnych zgosze poni偶ej 1000 s贸w, tekst mo偶e by atwo edytowany, aby zepsu obliczenia prawdopodobiestwa, a ze wzgldu na profesjonalnie skoncentrowany zestaw treningowy, ma wicej problem贸w z tekstem stworzonym przez dzieci lub osoby nie m贸wice po angielsku.

W tej chwili oznacza on tekst ludzki jako wygenerowany przez SI tylko w 9% przypadk贸w, a poprawnie identyfikuje tekst wygenerowany przez SI w ~26% przypadk贸w. Wraz ze wzrostem mocy i zakresu modelu liczby te ulegn poprawie, ale mo偶e si okaza, 偶e aby odpowiednio oceni, czy tekst jest generowany, czy nie, potrzebne s bardziej szczeg贸owe detektory.

# The Watermark Method

Jedna z metod wykrywania tekstu wygenerowanego przez AI wymaga wprowadzenia statystycznego znaku wodnego podczas generowania tekstu. Techniki te mog wykorzystywa "bia list" LLM, kt贸ra jest metod okrelania, czy tekst zosta wygenerowany przez okrelony model AI. Znak wodny dziaa poprzez wybranie randomizowanego zestawu "zielonych" token贸w przed wygenerowaniem sowa, a nastpnie mikkie promowanie u偶ycia wybranych token贸w podczas pr贸bkowania. Te wa偶one wartoci maj minimalny wpyw na jako generacji, ale mog by algorytmicznie wykryte przez inny LLM(@kirchenbauer2023watermarking).

Jest to intrygujcy pomys, ale wymaga, aby tw贸rcy modelu zaimplementowali ten framework do swojego LLM. Jeli model nie ma wbudowanego znaku wodnego, ta metoda nie bdzie dziaa.

# DetectGPT

Metoda [DetectGPT](https://detectgpt.ericmitchell.ai/)(@mitchell2023detectgpt) jest w stanie wykry tekst wygenerowany przez SI przy mniejszej iloci ustawie ni偶 poprzednie koncepcje. Naukowcy odkryli, 偶e generacje tekstu LLM maj tendencj do "zajmowania region贸w o negatywnej krzywi藕nie funkcji prawdopodobiestwa log modelu". Z tego powodu mo偶liwe jest stworzenie opartego na krzywi藕nie systemu do okrelania, czy blok tekstu zosta wygenerowany proceduralnie.

Dziaa poprzez obliczenie prawdopodobiestwa log z modelu, kt贸ry zosta uznany za generujcy tekst i por贸wnanie ich z losowymi zmianami tekstu z innego, wstpnie wytrenowanego modelu jzyka og贸lnego. W ten spos贸b DetectGPT jest w stanie zidentyfikowa prawdopodobiestwo wygenerowania fragmentu przy u偶yciu samych krzywych prawdopodobiestwa!

## Uwaga

Dodatkowe om贸wienie tematu czujek i tego, jak ludzie je oszukuj, mo偶na znale藕 w [tym artykule](https://learnprompting.org/docs/miscl/trickery).


