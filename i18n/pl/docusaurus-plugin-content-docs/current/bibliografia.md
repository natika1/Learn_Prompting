---
sidebar_position: 1000
---

#  Bibliografia

Strona zawiera zorganizowan list wszystkich papier贸w u偶ywanych przez ten kurs.
Referaty s uporzdkowane wedug temat贸w.

**Aby zacytowa ten kurs, u偶yj dostarczonego cytatu w repozytorium Github.

 = Referat bezporednio cytowany w tym kursie. Inne referaty poinformoway mnie o zrozumieniu tematu.

Uwaga: poniewa偶 [ani GPT-3 ani GPT-3 Instruct paper nie odpowiadaj modelom davinci](https://twitter.com/janleike/status/1584618242756132864), staram si nie
cytowa ich jako takich.

# Prompt Engineering Strategies

#### acuch myli(@wei2022chain) 

#### Zero Shot Chain of Thought(@kojima2022large) 

#### Self Consistency(@wang2022selfconsistency) 

#### What Makes Good In-Context Examples for GPT-3?(@liu2021makes) 

### Ask-Me-Anything Prompting(@arora2022ama) 

#### Generated Knowledge(@liu2021generated) 

#### Recitation-Augmented Language Models(@sun2022recitationaugmented) 

#### Rethinking the role of demonstrations(@min2022rethinking) 

#### Scratchpads(@nye2021work)

#### Maieutic Prompting(@jung2022maieutic)

#### STaR(@zelikman2022star)

#### Least to Most(@zhou2022leasttomost) 


## Niezawodno

#### MathPrompter(@imani2023mathprompter) 

#### The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning(@ye2022unreliability) 

#### Prompting GPT-3 do rzetelnoci(@si2022prompting)

#### Diverse Prompts(@li2022advance) 

#### Calibrate Before Use: Improving Few-Shot Performance of Language Models(@zhao2021calibrate) 

#### Wzmocniona samowiadomo(@mitchell2022enhancing)

#### Bias and Toxicity in Zero-Shot CoT(@shaikh2022second) 

#### Konstytucyjna AI: Bezszkodowo od AI Feedback (@bai2022constitutional) 

#### Compositional Generalization - SCAN(@lake2018scan)
## Automated Prompt Engineering

#### AutoPrompt(@shin2020autoprompt) 

#### Automatic Prompt Engineer(@zhou2022large)

## Modele

### Modele jzykowe

#### GPT-3(@brown2020language) 

#### GPT-3 Instrukta偶(@ouyang2022training) 

#### PaLM(@chowdhery2022palm) 

#### BLOOM(@scao2022bloom) 

#### BLOOM+1 (wicej jzyk贸w/ 0 ulepsze strza贸w)(@yong2022bloom1)

#### Jurassic 1(@lieberjurassic) 

#### GPT-J-6B(@wange2021gptj)

#### Roberta(@liu2019roberta)

### Image Models

#### Stable Diffusion(@rombach2021highresolution) 

#### DALLE(@ramesh2022hierarchical) 

# Soft Prompting

#### Soft Prompting(@lester2021power) .

#### Interpretowalne Dyskretne Mikkie Prompts(@khashabi2021prompt) .

## Datasets

#### MultiArith(@roy-roth-2015-rozwizanie) .

#### GSM8K(@cobbe2021training) 

#### HotPotQA(@yang2018hotpotqa) 

#### Fever(@thorne2018fever) 

#### BBQ: A Hand-Built Bias Benchmark for Question Answering (@parrish2021bbq) 

## Image Prompt Engineering

#### Taksonomia modyfikator贸w podpowiedzi (@oppenlaender2022taxonomy)

#### DiffusionDB(@wang2022diffusiondb)

#### The DALLE 2 Prompt Book(@parsons2022dalleprompt) 

#### Prompt Engineering for Text-Based Generative Art(@oppenlaender2022prompt) 

#### Z odpowiedni podpowiedzi, Stable Diffusion 2.0 mo偶e zrobi rce.(@blake2022with) 

#### Optimizing Prompts for Text-to-Image Generation (@hao2022optimizing)

## Prompt Engineering IDEs

#### Prompt IDE(@strobelt2022promptide) 

#### Prompt Source(@bach2022promptsource) 

#### PromptChainer(@wu2022promptchainer) 

#### PromptMaker(@jiang2022promptmaker) 

## Narzdzie

#### LangChain(@Chase_LangChain_2022) 

#### TextBox 2.0: A Text Generation Library with Pre-trained Language Models(@tang2022textbox) 

#### OpenPrompt: An Open-source Framework for Prompt-learning(@ding2021openprompt) 

#### GPT Index(@Liu_GPT_Index_2022) 

# Applied Prompt Engineering

#### Language Model Cascades(@dohan2022language)

#### MRKL(@karpas2022mrkl) 

#### ReAct(@yao2022react) 

#### PAL: Program-aided Language Models(@gao2022pal) .

## Projektowanie interfejsu u偶ytkownika

#### Design Guidelines for Prompt Engineering Text-to-Image Generative Models (@liu2022design)

# Prompt Injection

#### Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods(@crothers2022machine) 

#### Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples(@branch2022evaluating) 

#### Prompt injection attacks against GPT-3(@simon2022inject) 

#### Wykorzystanie podpowiedzi GPT-3 ze zoliwymi wejciami, kt贸re nakazuj modelowi zignorowa jego poprzednie wskaz贸wki(@goodside2022inject) 

#### adversarial-prompts(@chase2021adversarial) 

#### GPT-3 Prompt Injection Defenses(@goodside2021gpt) 

#### Rozmowy z maszynami: prompt engineering & injection(@christoph2022talking)

#### Exploring Prompt Injection Attacks(@selvi2022exploring) 

#### U偶ywanie GPT-Eliezer przeciwko ChatGPT Jailbreaking(@armstrong2022using) 

#### Microsoft Bing Chat Prompt(@kevinbing)

# Jailbreaking

#### Ignore Previous Prompt: Attack Techniques For Language Models(@perez2022jailbreak)

#### Wnioski dotyczce bezpieczestwa i niewaciwego u偶ycia modeli jzykowych (@brundage_2022)

#### Toxicity Detection with Generative Prompt-based Inference (@wang2022jailbreak)

#### Nowe i ulepszone narzdzia do moderacji treci(@markov_2022)

#### OpenAI API(@openai_api) 

#### OpenAI ChatGPT(@openai_chatgpt) 

#### ChatGPT 4 Tweet(@alice2022jailbreak) 

#### Aktorski Tweet(@miguel2022jailbreak) 

#### Research Tweet(@derek2022jailbreak) 

#### Pretend Ability Tweet(@nero2022jailbreak) 

#### Odpowiedzialno Tweet(@nick2022jailbreak) 

#### Lynx Mode Tweet(@jonas2022jailbreak) 

#### Sudo Mode Tweet(@sudo2022jailbreak) 

#### Ignore Previous Prompt(@ignore_previous_prompt) 

#### Updated Jailbreaking Prompts (@AI_jailbreak) .

## Surveys

#### Pre-train, Prompt, and Predict: Systematyczny przegld metod promowania w przetwarzaniu jzyka naturalnego (@liu2021pretrain)

#### PromptPapers(@ning2022papers)

## Dataset Generation

#### Odkrywanie zachowa modeli jzykowych za pomoc ocen pisanych przez model (@perez2022discovering)

#### Selective Annotation Makes Language Models Better Few-Shot Learners(@su2022selective)

## Aplikacje

#### Atlas: Few-shot Learning with Retrieval Augmented Language Models(@izacard2022atlas)

#### STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension(@wang2022strudel)

## Miscl

#### Prompting Is Programming: A Query Language For Large Language Models(@beurerkellner2022prompting)

#### Parallel Context Windows Improve In-Context Learning of Large Language Models (@ratner2022parallel)

#### Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models(@bursztyn2022learning)

#### Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks (@wang2022supernaturalinstructions)

#### Making Pre-trained Language Models Better Few-shot Learners (@gao2021making)

#### Uziemienie z wynikami wyszukiwania(@livin2022large)

#### How to Prompt? Mo偶liwoci i wyzwania zwizane z uczeniem si od zera i kilku uj dla interakcji czowiek-istota w kreatywnych zastosowaniach modeli generatywnych (@dang2022prompt)

#### O mierzeniu spoecznych uprzedze w wielozadaniowym uczeniu si opartym na promptach (@akyrek2022measuring)

#### Plot Writing From Pre-Trained Language Models(@jin2022plot) 

#### StereoSet: Measuring stereotypical bias in pretrained language models(@nadeem-etal-2021-stereoset)

#### Badanie halucynacji w generowaniu jzyka naturalnego(@Ji_2022)

#### Przykady(@2022examples)

#### Wordcraft(@yuan2022wordcraft)

#### PainPoints(@fadnavis2022pain)

#### Self-Instruct: Aligning Language Model with Self Generated Instructions(@wang2022selfinstruct)

#### From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models(@guo2022images)

#### Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference (@schick2020exploiting)

### Ask-Me-Anything Prompting(@arora2022ama)

### A Watermark for Large Language Models(@kirchenbauer2023watermarking)

