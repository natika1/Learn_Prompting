---
sidebar_position: 3
locale: en-us
styl: chicago
---

# üü¢ Chain of Thought Prompting

≈Åa≈Ñcuch my≈õli (CoT) (@wei2022chain) jest niedawno opracowanƒÖ metodƒÖ podpowiadania.
kt√≥ra zachƒôca LLM do wyja≈õnienia swojego rozumowania. Poni≈ºszy obrazek(@wei2022chain)
pokazuje %%few shot standard prompt|few shot standard prompt%% (po lewej) w por√≥wnaniu do chain of thought prompt (po prawej).


import CoTExample from '@site/docs/assets/chain_of_thought_example.png';

<div style={{textAlign: 'center'}}>.
  <img src={CoTExample} style={{szeroko≈õƒá: "750px"}} />
</div>

<div style={{textAlign: 'center'}}>
Regular Prompting vs CoT (Wei et al.)
</div>

G≈Ç√≥wna idea CoT polega na tym, ≈ºe pokazujƒÖc LLM kilka strza≈Ç√≥w %%exemplars|exemplars%%, gdzie proces rozumowania jest wyja≈õniony w exemplars, LLM poka≈ºe r√≥wnie≈º proces rozumowania.
w kt√≥rych proces rozumowania jest wyja≈õniony w przyk≈Çadach, LLM poka≈ºe r√≥wnie≈º proces rozumowania
podczas odpowiadania na podpowied≈∫. To wyja≈õnienie rozumowania czƒôsto prowadzi do bardziej dok≈Çadnych
wynik√≥w.

## Przyk≈Çad.

Oto kilka demek. Pierwsze pokazuje GPT-3 (davinci-003)
nie radzi sobie z rozwiƒÖzaniem prostego zadania s≈Çownego. Drugie pokazuje GPT-3 (davinci-003), kt√≥ry z powodzeniem rozwiƒÖzuje to samo zadanie, u≈ºywajƒÖc podpowiedzi CoT.

#### Nieprawid≈Çowo

<div trydyno-embed="" openai-model="text-davinci-003" initial-prompt="Kt√≥ry spos√≥b dotarcia do pracy jest szybszy?" initial-response="Opcja 1: Jed≈∫ 1000 minutowym autobusem, potem p√≥≈Çgodzinnym pociƒÖgiem, a na koniec 10 minut jazdy rowerem.\Opcja 2: Jed≈∫ 800 minut autobusem, potem p√≥≈Ç godziny pociƒÖgiem, a na koniec 30 minut rowerem." initial-response="Opcja 1 jest szybszym sposobem dotarcia do pracy." max-tokens="256" box-rows="7" model-temp="0" top-p="0"></div>

#### Prawid≈Çowo

<div trydyno-embed="" openai-model="text-davinci-003" initial-prompt="Kt√≥ry spos√≥b dotarcia do domu jest szybszy?\NOpcja 1: We≈∫ 10 minutowy autobus, nastƒôpnie 40 minutowy autobus, a na koniec 10 minutowy pociƒÖg.\NOpcja 2: We≈∫ 90 minutowy pociƒÖg, nastƒôpnie 45 minutowƒÖ przeja≈ºd≈ºkƒô rowerem, a na koniec 10 minutowy autobus.\NOpcja 1 zajmie 10+40+10 = 60 minut.\NOpcja 2 zajmie 90+45+10=145 minut.\NPoniewa≈º opcja 1 trwa 60 minut, a opcja 2 145 minut, opcja 1 jest szybsza.\NKt√≥ra z nich jest szybszym sposobem dotarcia do pracy? \NOpcja 1: Jed≈∫ 1000 minut autobusem, potem p√≥≈Çgodzinnym pociƒÖgiem, a na koniec 10 minut rowerem.\NOpcja 2: Jed≈∫ 800 minut autobusem, potem godzinnym pociƒÖgiem, a na koniec 30 minut rowerem." initial-response="Opcja 1 zajmie 1000+30+10 = 1040 minut.
Opcja 2 zajmie 800+60+30 = 890 minut.
Poniewa≈º opcja 2 zajmuje 890 minut, a opcja 1 zajmuje 1040 minut, opcja 2 jest szybsza." max-tokens="256" box-rows="18" model-temp="0" top-p="0"></div>

## Wyniki

Wykazano, ≈ºe CoT jest skuteczny w poprawianiu wynik√≥w w zadaniach np.
arytmetyka, rozumowanie i rozumowanie symboliczne (@wei2022chain).
W szczeg√≥lno≈õci, podpowiadany PaLM 540B(@chowdhery2022palm) osiƒÖga 57% dok≈Çadno≈õci rozwiƒÖzania
w GSM8K(@cobbe2021training) (SOTA w tym czasie).

import PromptedPaLM from '@site/docs/assets/prompted_palm.png';

<div style={{textAlign: 'center'}}>.
  <img src={PromptedPaLM} style={{width: "300px"}} />
</div>

<div style={{textAlign: 'center'}}>
Por√≥wnanie modeli na benchmarku GSM8K (Wei i in.)
</div>

## Ograniczenia

Co wa≈ºne, wed≈Çug Wei i in. "CoT daje wzrost wydajno≈õci tylko wtedy, gdy jest stosowany z modelami o parametrach ‚àº100B". Mniejsze modele pisa≈Çy nielogiczne ≈Ça≈Ñcuchy my≈õlowe, co prowadzi≈Ço do gorszej dok≈Çadno≈õci ni≈º standardowe podpowiadanie. Modele zazwyczaj uzyskujƒÖ wzrost wydajno≈õci dziƒôki podpowiedziom CoT w spos√≥b proporcjonalny do wielko≈õci modelu.


## Notes

≈ªadne modele jƒôzykowe nie zosta≈Çy ~~hurt~~ finetuned w procesie pisania tego rozdzia≈Çu üòä.

