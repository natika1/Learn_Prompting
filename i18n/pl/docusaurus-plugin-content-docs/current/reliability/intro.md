---
sidebar_position: 1
---

#  Wstp

W tym rozdziale om贸wiono, jak zwikszy wiarygodno uzupenie oraz jak
jak wdro偶y kontrole, aby upewni si, 偶e dane wyjciowe s wiarygodne.

W pewnym stopniu wikszo
wikszo poprzednich technik, o kt贸rych mowa, ma zwizek z popraw dokadnoci uzupeniania
dokadnoci, a tym samym niezawodnoci, w szczeg贸lnoci self-consistency(@wang2022selfconsistency).
Istnieje jednak szereg innych technik, kt贸re mo偶na wykorzysta do poprawy niezawodnoci,
poza podstawowymi strategiami podpowiadania.

%%LLMs|LLM%% wykazuj r贸偶ne problemy, w tym halucynacje(@webson2023itscomplicated),
bdne wyjanienia za pomoc metod %%CoT|CoT prompting%%(@ye2022unreliability), oraz wiele bd贸w (bias).
w tym majority label bias, recency bias i common token bias(@zhao2021calibrate).
Dodatkowo, zero-shot CoT mo偶e by szczeg贸lnie stronniczy, gdy mamy do czynienia z wra偶liwymi tematami
(@shaikh2022second).

Wsp贸lne rozwizania niekt贸rych z tych problem贸w obejmuj kalibratory do usuwania uprzedze,
i weryfikator贸w do oceny uzupenie, jak r贸wnie偶 promowanie r贸偶norodnoci w uzupenieniach.


